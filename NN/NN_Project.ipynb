{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, GridSearchCV, cross_val_predict\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer\n",
        "from skopt import BayesSearchCV, gp_minimize, forest_minimize, gbrt_minimize, dummy_minimize\n",
        "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
        "from skopt.utils import use_named_args\n",
        "from skopt import Optimizer\n",
        "import numpy as np\n",
        "import pyswarm\n",
        "from pyswarm import pso\n"
      ],
      "metadata": {
        "id": "u4A4NEcfq6hg"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('clean_data (copy).csv')\n",
        "X = data.drop('target', axis=1)  # Drop the target column\n",
        "y = data['target']"
      ],
      "metadata": {
        "id": "LYyXNwvCq9IH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters for grid search\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(16,), (32,), (64,)],\n",
        "    'activation': ['relu', 'tanh', 'logistic'],\n",
        "    'solver': ['adam', 'sgd'],\n",
        "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
        "    'max_iter': [10000],  # Adjusted max_iter\n",
        "    'alpha': [0.0001, 0.001, 0.01]  # Regularization parameter\n",
        "}"
      ],
      "metadata": {
        "id": "jAFFrU3mrV3j"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-fold cross-validation\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n"
      ],
      "metadata": {
        "id": "FVAPyQMhrYOZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store predictions\n",
        "predictions = {}"
      ],
      "metadata": {
        "id": "b7_R5Gq8rcEZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define MLPRegressor model directly\n",
        "mlp_model = MLPRegressor()  # Updated model definition"
      ],
      "metadata": {
        "id": "OC0CmqAMrd_L"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid Search\n",
        "grid_search = GridSearchCV(estimator=mlp_model, param_grid=param_grid, cv=kfold, scoring='neg_mean_squared_error', verbose=1)\n",
        "grid_search.fit(X, y)\n",
        "best_model = grid_search.best_estimator_\n",
        "predictions['MLP_GridSearch'] = cross_val_predict(best_model, X, y, cv=kfold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URe1jVdrrfln",
        "outputId": "e89d7976-fa21-40aa-8e7a-ab3c42bde144"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameter search spaces\n",
        "param_space = {\n",
        "    'hidden_layer_sizes': Integer(16, 64),\n",
        "    'activation': ['relu', 'tanh', 'logistic'],\n",
        "    'solver': ['adam', 'sgd'],\n",
        "    'learning_rate_init': Real(0.001, 0.1, prior='log-uniform'),\n",
        "    'max_iter': [10000],\n",
        "    'alpha': Real(0.0001, 0.01, prior='log-uniform')\n",
        "}"
      ],
      "metadata": {
        "id": "6JShK7rzz3fd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Search\n",
        "random_search = BayesSearchCV(\n",
        "    estimator=mlp_model,\n",
        "    search_spaces=param_space,\n",
        "    n_iter=20,\n",
        "    cv=kfold,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n",
        "random_search.fit(X, y)\n",
        "predictions['RandomSearch'] = cross_val_predict(random_search.best_estimator_, X, y, cv=kfold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrhbXZOdx4Yb",
        "outputId": "98735756-b112-43c0-9a64-823662c2dcae"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperband\n",
        "def hyperband_objective(space):\n",
        "    mlp = MLPRegressor(hidden_layer_sizes=space['hidden_layer_sizes'],\n",
        "                      activation=space['activation'],\n",
        "                      solver=space['solver'],\n",
        "                      learning_rate_init=space['learning_rate_init'],\n",
        "                      max_iter=space['max_iter'],\n",
        "                      alpha=space['alpha'])\n",
        "\n",
        "    mse = cross_val_predict(mlp, X, y, cv=kfold)\n",
        "    return {'loss': -np.mean(mse), 'status': STATUS_OK}\n",
        "\n",
        "hyperband_space = {\n",
        "    'hidden_layer_sizes': hp.randint('hidden_layer_sizes', 16, 64),\n",
        "    'activation': hp.choice('activation', ['relu', 'tanh', 'logistic']),\n",
        "    'solver': hp.choice('solver', ['adam', 'sgd']),\n",
        "    'learning_rate_init': hp.loguniform('learning_rate_init', np.log(0.001), np.log(0.1)),\n",
        "    'max_iter': 10000,\n",
        "    'alpha': hp.loguniform('alpha', np.log(0.0001), np.log(0.01))\n",
        "}\n",
        "\n",
        "hyperopt_trials = Trials()\n",
        "hyperopt_best = fmin(fn=hyperband_objective,\n",
        "                      space=hyperband_space,\n",
        "                      algo=tpe.suggest,\n",
        "                      max_evals=20,\n",
        "                      trials=hyperopt_trials)\n",
        "best_hyperband_model = MLPRegressor(hidden_layer_sizes=hyperopt_best['hidden_layer_sizes'],\n",
        "                                    activation=['relu', 'tanh', 'logistic'][hyperopt_best['activation']],\n",
        "                                    solver=['adam', 'sgd'][hyperopt_best['solver']],\n",
        "                                    learning_rate_init=hyperopt_best['learning_rate_init'],\n",
        "                                    max_iter=10000,\n",
        "                                    alpha=hyperopt_best['alpha'])\n",
        "predictions['Hyperband'] = cross_val_predict(best_hyperband_model, X, y, cv=kfold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXq_7Hnsz-dU",
        "outputId": "1580be59-ac02-481d-d682-6be0ba7b5337"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 20/20 [00:32<00:00,  1.61s/trial, best loss: -9592648522.240143]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameter search spaces\n",
        "param_space = [\n",
        "    Integer(16, 64, name='hidden_layer_sizes'),\n",
        "    Real(0.001, 0.1, prior='log-uniform', name='learning_rate_init'),\n",
        "    Real(0.0001, 0.01, prior='log-uniform', name='alpha')\n",
        "]\n"
      ],
      "metadata": {
        "id": "NjXw3auM1LcX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BO-TPE\n",
        "@use_named_args(param_space)\n",
        "def bo_tpe_objective(hidden_layer_sizes, learning_rate_init, alpha):\n",
        "    mlp = MLPRegressor(hidden_layer_sizes=int(hidden_layer_sizes),\n",
        "                       learning_rate_init=learning_rate_init,\n",
        "                       alpha=alpha,\n",
        "                       max_iter=10000)\n",
        "\n",
        "    mse = cross_val_predict(mlp, X, y, cv=kfold)\n",
        "    return -np.mean(mse)  # Minimize negative mean squared error\n",
        "\n",
        "bo_tpe = forest_minimize(bo_tpe_objective, param_space, n_calls=20, random_state=42)\n",
        "\n",
        "best_bo_tpe_model = MLPRegressor(hidden_layer_sizes=int(bo_tpe.x[0]),\n",
        "                                 learning_rate_init=bo_tpe.x[1],\n",
        "                                 alpha=bo_tpe.x[2],\n",
        "                                 max_iter=10000)\n",
        "\n",
        "predictions['BO_TPE'] = cross_val_predict(best_bo_tpe_model, X, y, cv=kfold)"
      ],
      "metadata": {
        "id": "BVxIx1iQ049Z"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BO-GP\n",
        "@use_named_args(param_space)\n",
        "def bo_gp_objective(hidden_layer_sizes, learning_rate_init, alpha):\n",
        "    mlp = MLPRegressor(hidden_layer_sizes=int(hidden_layer_sizes),\n",
        "                       learning_rate_init=learning_rate_init,\n",
        "                       alpha=alpha,\n",
        "                       max_iter=10000)\n",
        "\n",
        "    mse = cross_val_predict(mlp, X, y, cv=kfold)\n",
        "    return np.mean(mse)  # Minimize mean squared error\n",
        "\n",
        "bo_gp = gp_minimize(bo_gp_objective, param_space, n_calls=20, random_state=42)\n"
      ],
      "metadata": {
        "id": "hHQN-yyC2J3r"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the objective function for PSO\n",
        "def pso_objective(x):\n",
        "    mlp = MLPRegressor(hidden_layer_sizes=int(x[0]),\n",
        "                       learning_rate_init=x[1],\n",
        "                       alpha=x[2],\n",
        "                       max_iter=10000)\n",
        "\n",
        "    mse = cross_val_predict(mlp, X, y, cv=kfold)\n",
        "    return np.mean(mse)\n",
        "\n",
        "# Define the bounds for PSO\n",
        "lower_bound = [16, 0.001, 0.0001]\n",
        "upper_bound = [64, 0.1, 0.01]\n",
        "\n",
        "# Perform PSO optimization\n",
        "pso_result = pso(pso_objective, lower_bound, upper_bound, swarmsize=20, maxiter=20)\n",
        "\n",
        "# Extract the optimal hyperparameters\n",
        "optimal_hidden_layer_sizes = int(pso_result[0][0])\n",
        "optimal_learning_rate_init = pso_result[0][1]\n",
        "optimal_alpha = pso_result[0][2]\n",
        "\n",
        "\n",
        "# Create MLPRegressor with optimal hyperparameters\n",
        "best_pso_model = MLPRegressor(hidden_layer_sizes=optimal_hidden_layer_sizes,\n",
        "                              learning_rate_init=optimal_learning_rate_init,\n",
        "                              alpha=optimal_alpha,\n",
        "                              max_iter=10000)\n",
        "\n",
        "# Perform cross-validation predictions\n",
        "predictions['PSO'] = cross_val_predict(best_pso_model, X, y, cv=kfold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJ9F88EE2pky",
        "outputId": "2a4fed41-7991-4360-ae18-600b342c139a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopping search: maximum iterations reached --> 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save predictions to CSV files\n",
        "for technique, pred_values in predictions.items():\n",
        "    df = pd.DataFrame({'Actual': y, 'Predicted': pred_values})\n",
        "    df.to_csv(technique + '_predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "t3kRvtJ7u61j"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}